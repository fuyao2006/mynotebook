Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: 2017-09-29T19:54:52+08:00

====== hadoop集群安装 ======
创建日期 星期五 29 九月 2017

-

1.MapReduce任务报No FileSystem for scheme: hdfs错误
 通过配置core-site.xml，加入以下内容：
<property>
<name>fs.file.impl</name>
<value>org.apache.hadoop.fs.LocalFileSystem</value>
<description>The FileSystem for file: uris.</description>
</property>

<property>
<name>fs.hdfs.impl</name>
<value>org.apache.hadoop.hdfs.DistributedFileSystem</value>
<description>The FileSystem for hdfs: uris.</description>
</property>

以下3条参考：www.jianshu.com/p/ce69b9c21f1d


2.修改core-site.xml
<property> 
<name>hadoop.tmp.dir</name> 
<value>file:/usr/local/hadoop/tmp</value>
<description>Abase for other temporary directories.</description>
</property>

 <property>
 <name>fs.defaultFS</name> 
<!-- 修改localhost为master--> 
<value>hdfs://master:9000</value> 
</property>

<property>    
		 <name>io.file.buffer.size</name>    
		 <value>131072</value>    
	</property>  

3.修改mapred-site.xml
<configuration> 
<!--新框架支持第三方 MapReduce 开发框架以支持如 SmartTalk/DGSG 等非 Yarn 架构，注意通常情况下这个配置的值都设置为 Yarn，如果没有配置这项，那么提交的 Yarn job 只会运行在 locale 模式，而不是分布式模式。--> 
<property> 
<name>mapreduce.framework.name</name>
 <value>yarn</value>
 </property>

 <!--添加此属性以便远程创建MapReduce Job使用--> 
<property> 
<name>mapreduce.jobtracker.address</name> 
<value>master:9001</value> 
</property> 

</configuration>

3.修改yarn-site.xml

<configuration> 
<!-- Site specific YARN configuration properties --> 
<property> 
<name>yarn.nodemanager.aux-services</name> 
<value>mapreduce_shuffle</value> 
</property> 

<property>
<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
<value>org.apache.hadoop.mapred.ShuffleHandler</value>
</property>

  
         

以下非必须
<!--指定Yarn的老大(ResourceManager)的地址-->     
<property>    
  <name>yarn.resourcemanager.address</name>    
  <value>hadoop-host:18040</value>    
</property>    
<property>    
  <name>yarn.resourcemanager.scheduler.address</name>    
  <value>hadoop-host:18030</value>    
</property>    
<property>    
  <name>yarn.resourcemanager.webapp.address</name>    
  <value>hadoop-host:18088</value>    
</property>    
<property>    
  <name>yarn.resourcemanager.resource-tracker.address</name>    
  <value>hadoop-host:18025</value>    
</property>    
<property>    
  <name>yarn.resourcemanager.admin.address</name>    
  <value>hadoop-host:18141</value>    
</property>    
<property>    


</configuration>

4.hdfs-site.xml
<property>
<name>dfs.namenode.name.dir</name>
<value>/mnt/disk1/yarn/dfs/name</value>
</property>

<property>
<!-- 真正的datanode数据保存路径，可以写多块硬盘，逗号分隔.把这些位置分散在每个节点上的所有磁盘上可以实现磁盘 I/O 平衡，因此会显著改进磁盘 I/O 性能。  -->
<name>dfs.datanode.data.dir</name>
<value>/mnt/disk1/yarn/dfs/data</value>
</property>
<property>

<property>
<name>dfs.replication</name>
<value>1</value>
</property>

	<property>    
			 <name>dfs.webhdfs.enabled</name>    
			 <value>true</value>    
		</property>   


<property>
<name>dfs.permissions</name>
<value>false</value>
</property>

5.修改主机名：修改hostname文件

修改/etc/host，注意请在host文件中一并添加hadoopnode1机器的IP地址。

10.10.11.225 Hadoop-host
10.10.11.254 hadoopnode1
::1         localhost

masters文件：配置主节点ip或者host 同slaves 可以不配置

修改slaves
在slaves文件中添加你的节点ip或者host：每行一个主机名或ip（集群的全部包含主机和从机）
YARN001

如果在slaves文件里面没有包含Hadoop主机IP，那么启动时会只有一个datanode.

至此Hadoop配置工作告一段落。

6.hadoop-env.sh

export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-2.b11.el7_3.x86_64/jre

即与系统的环境变量JAVA_HOME保持一致。

找一个国内的Hadoop镜像站点，下载hadoop后，解压到指定目录（本示例解压到：/usr/hadoop），然后打开文件/etc/profile，并在文件最后添加：

export HADOOP_HOME=/usr/hadoop  
export PATH=$PATH:$HADOOP_HOME/bin



7. 分发配置  scp –r /usr/hadoop root@hadoopnode1 :/usr/，将hadoop配置分发至hadoopnode1节点计算机。











