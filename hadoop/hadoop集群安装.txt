Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: 2017-09-29T19:54:52+08:00

====== hadoop集群安装 ======
创建日期 星期五 29 九月 2017

-

1.MapReduce任务报No FileSystem for scheme: hdfs错误
 通过配置core-site.xml，加入以下内容：
<property>
<name>fs.file.impl</name>
<value>org.apache.hadoop.fs.LocalFileSystem</value>
<description>The FileSystem for file: uris.</description>
</property>

<property>
<name>fs.hdfs.impl</name>
<value>org.apache.hadoop.hdfs.DistributedFileSystem</value>
<description>The FileSystem for hdfs: uris.</description>
</property>

以下3条参考：www.jianshu.com/p/ce69b9c21f1d


2.修改core-site.xml
<property> 
<name>hadoop.tmp.dir</name> 
<value>file:/usr/local/hadoop/tmp</value>
<description>Abase for other temporary directories.</description>
</property>

 <property>
 <name>fs.defaultFS</name> 
<!-- 修改localhost为master--> 
<value>hdfs://master:9000</value> 
</property>

<property>    
		 <name>io.file.buffer.size</name>    
		 <value>131072</value>    
	</property>  

3.修改mapred-site.xml
<configuration> 
<!--新框架支持第三方 MapReduce 开发框架以支持如 SmartTalk/DGSG 等非 Yarn 架构，注意通常情况下这个配置的值都设置为 Yarn，如果没有配置这项，那么提交的 Yarn job 只会运行在 locale 模式，而不是分布式模式。--> 
<property> 
<name>mapreduce.framework.name</name>
 <value>yarn</value>
 </property>

 <!--添加此属性以便远程创建MapReduce Job使用--> 
<property> 
<name>mapreduce.jobtracker.address</name> 
<value>master:9001</value> 
</property> 

</configuration>

3.修改yarn-site.xml
<configuration> 
<!-- Site specific YARN configuration properties --> 
<property> 
<name>yarn.nodemanager.aux-services</name> 
<value>mapreduce_shuffle</value> 
</property> 

<property>
<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
<value>org.apache.hadoop.mapred.ShuffleHandler</value>
</property>


</configuration>

4.hdfs-site.xml
<property>
<name>dfs.namenode.name.dir</name>
<value>/mnt/disk1/yarn/dfs/name</value>
</property>
<property>
<name>dfs.datanode.data.dir</name>
<value>/mnt/disk1/yarn/dfs/data</value>
</property>
<property>

<property>
<name>dfs.replication</name>
<value>1</value>
</property>

	<property>    
			 <name>dfs.webhdfs.enabled</name>    
			 <value>true</value>    
		</property>   


<property>
<name>dfs.permissions</name>
<value>false</value>
</property>

5.修改主机名：修改hostname文件

修改/etc/host，注意请在host文件中一并添加hadoopnode1机器的IP地址。

10.10.11.225 Hadoop-host
10.10.11.254 hadoopnode1
::1         localhost

修改slaves
在slaves文件中添加你的节点ip或者host：每行一个主机名或ip
YARN001
